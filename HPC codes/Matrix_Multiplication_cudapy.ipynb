{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLwiefGb-C4d","outputId":"11e7c677-e6bd-42d0-9b5e-4c1fe7817372","executionInfo":{"status":"ok","timestamp":1745940034272,"user_tz":-330,"elapsed":8188,"user":{"displayName":"Aditya Pasarkar","userId":"08640866093582653490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/afnan47/cuda.git\n","  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-uqfnkbzc\n","  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-uqfnkbzc\n","  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4290 sha256=8234e26c5b49ef663ee8204ecf25b30e4c094860eee0c6b3d333688308ba969c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-hooitdyp/wheels/bc/4e/e0/2d86bd15f671dbeb32144013f1159dba09757fde36dc51a963\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}],"source":["# Set up CUDA\n","#First Change runtime to GPU and run this cell\n","!pip install git+https://github.com/afnan47/cuda.git\n","%load_ext nvcc_plugin\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eOwFLYHJAJe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0f6b119-bacb-4feb-92ae-a8975acc56c9","executionInfo":{"status":"ok","timestamp":1745940211148,"user_tz":-330,"elapsed":138203,"user":{"displayName":"Aditya Pasarkar","userId":"08640866093582653490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pycuda\n","  Downloading pycuda-2025.1.tar.gz (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2025.1.2-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n","Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.2)\n","Downloading pytools-2025.1.2-py3-none-any.whl (92 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2025.1-cp311-cp311-linux_x86_64.whl size=660425 sha256=6aa9910f32964764f7b8e7f2cea59ef496d298fea1641833e201488c6625b1fa\n","  Stored in directory: /root/.cache/pip/wheels/77/7e/6c/d2d1451ea6424cdc3d67b36c16fa7111eafdf2034bc3405666\n","Successfully built pycuda\n","Installing collected packages: pytools, pycuda\n","Successfully installed pycuda-2025.1 pytools-2025.1.2\n"]}],"source":["pip install pycuda\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ebqsk_UBG-be","outputId":"8297cbef-3d2f-4204-ca0d-54a680f16075","executionInfo":{"status":"ok","timestamp":1745940347656,"user_tz":-330,"elapsed":1422,"user":{"displayName":"Aditya Pasarkar","userId":"08640866093582653490"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix A:\n","9 9 7 8\n","5 7 3 4\n","4 4 1 3\n","9 4 8 2\n","Matrix B:\n","4 8 3 8\n","0 6 4 8\n","4 3 3 2\n","2 0 1 6\n","Matrix multiplication result (C = A * B):\n","80 147 92 206\n","40 91 56 126\n","26 59 34 84\n","72 120 69 132\n"]}],"source":["import pycuda.driver as cuda\n","import pycuda.autoinit\n","import numpy as np\n","from pycuda.compiler import SourceModule\n","\n","# Define CUDA kernel for matrix multiplication\n","kernel_code = \"\"\"\n","__global__ void matmul(int *A, int *B, int *C, int N)\n","{\n","    int row = threadIdx.y + blockIdx.y * blockDim.y;\n","    int col = threadIdx.x + blockIdx.x * blockDim.x;\n","\n","    if (row < N && col < N)\n","    {\n","        int sum = 0;\n","        for (int i = 0; i < N; i++)\n","        {\n","            sum += A[row * N + i] * B[i * N + col];\n","        }\n","        C[row * N + col] = sum;\n","    }\n","}\n","\"\"\"\n","\n","# Initialize matrices with random values\n","def initialize_matrix(N):\n","    return np.random.randint(0, 10, (N, N)).astype(np.int32)\n","\n","# Print matrix\n","def print_matrix(mat):\n","    for row in mat:\n","        print(\" \".join(map(str, row)))\n","\n","# Matrix size (NxN)\n","N = 4\n","\n","# Initialize matrices A and B\n","A = initialize_matrix(N)\n","B = initialize_matrix(N)\n","\n","# Print matrices A and B\n","print(\"Matrix A:\")\n","print_matrix(A)\n","print(\"Matrix B:\")\n","print_matrix(B)\n","\n","# Allocate memory on the device\n","A_gpu = cuda.mem_alloc(A.nbytes)\n","B_gpu = cuda.mem_alloc(B.nbytes)\n","C_gpu = cuda.mem_alloc(A.nbytes)\n","\n","# Copy input matrices to the device\n","cuda.memcpy_htod(A_gpu, A)\n","cuda.memcpy_htod(B_gpu, B)\n","\n","# Compile the CUDA code\n","mod = SourceModule(kernel_code)\n","\n","# Get the kernel function\n","matmul_kernel = mod.get_function(\"matmul\")\n","\n","# Define number of threads per block and blocks per grid\n","threads_per_block = (16, 16, 1)  # Block size (16x16 threads per block)\n","blocks_per_grid = (int(np.ceil(N / threads_per_block[0])),\n","                   int(np.ceil(N / threads_per_block[1])))  # Grid size\n","\n","# Launch the CUDA kernel\n","matmul_kernel(A_gpu, B_gpu, C_gpu, np.int32(N), block=threads_per_block, grid=blocks_per_grid)\n","\n","# Copy the result from device to host\n","C = np.empty_like(A)\n","cuda.memcpy_dtoh(C, C_gpu)\n","\n","# Print the result\n","print(\"Matrix multiplication result (C = A * B):\")\n","print_matrix(C)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}